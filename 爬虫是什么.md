#### 爬虫是什么:

```
爬取网页上的文字,图片,视频,音频
自动化操作浏览器,比如填写表单,打卡,提高工作效率
```

#### 爬虫的注意事项:

```
爬虫前阅读robots.txt
注意遵守相关法律规定
反爬:防止爬虫程序对网站数据就行爬取
反反爬:破解网站中的反爬机制,获取相关数据
```

#### 什么是HTTP协议:

```
HTTP协议:HyperText Transfer Protocol,超文本传输协议,发布和接收HTML的协议,服务器端口号:80端口
HTTPS协议:HTTP协议的加密版本,在HTTP下加入了SSL层,服务器端口号:443
```

我们平时输入网址时不需要手动输入端口号,浏览器会自动识别,例如下图,CSDN使用的是HTTPS协议,我们可以手动输入:443,按下回车,仍可访问网页

![image](https://github.com/user-attachments/assets/5cd1eaa0-796a-43a2-9c6e-351f27b0c33b)


输入错误的端口号,会加载失败,例如我们输入:80,会显示响应无效

![image-20240722100136933](C:\Users\liu\AppData\Roaming\Typora\typora-user-images\image-20240722100136933.png)

#### 什么是URL:

```
URL:Uniform Resource Locator,统一资源定位符
scheme://host:port/path/?query-string=xxx#anchor
scheme:访问的协议,常见的协议:http,https,ftp
host:主机名,域名,比如www.taobao.com
port:端口号,默认80或443
path:查找路径,sz.58.com/chuzu ,这里的chuzu就是path
query-string:查询字符串,www.baidu.com/s?wd=python,后面的wd=python就是查询字符串
anchor:锚点,前端用作页面定位用的,现在一些前后端分离项目,也用锚点来做导航
```

#### 常见请求方法:

Requests Method:HTTP协议定义了8种请求方法,**最常用的四种请求方法：GET, POST, PUT, DELETE**,

剩下四种不常用的请求方法:HEAD、‌OPTIONS、‌TRACE和CONNECT,下面介绍一下get请求和post请求

```
get请求:一般情况下,只从服务器获取数据下来,并不会对服务器资源长生任何影响的时候会使用get请求
post请求:向服务器发送数据(登录),上传文件.会对服务器资源产生影响的时候使用post请求
```

###### ==如何查看请求方式==：

打开浏览器,进行网页搜索,单击鼠标右键,选择最下方的"检查"

![image-20240722102759633](C:\Users\liu\AppData\Roaming\Typora\typora-user-images\image-20240722102759633.png)

①选择Network

②刷新网页

③选择第一个文件,点击后就可以查看请求方法是“GET"

![image-20240722103326973](C:\Users\liu\AppData\Roaming\Typora\typora-user-images\image-20240722103326973.png)

![image-20240722104154760](C:\Users\liu\AppData\Roaming\Typora\typora-user-images\image-20240722104154760.png)

登录界面通常会产生"POST"请求,随便输入账号试一试,显示的是”POST“请求

![image-20240722104154760](C:\Users\liu\AppData\Roaming\Typora\typora-user-images\image-20240722104154760.png)

#### 请求头参数:

```
User-Agent:浏览器名称,网络爬虫中经常使用到,请求一个网页时,服务器通过这个参数就可以知道是哪种服务器发送的
通过爬虫发送的请求,User-Agent是Python,为了避免反爬,通常设置为一些浏览器的值来伪装爬虫

Referer:表明当前这个请求从哪个url过来的,对于反爬中,如果不是从指定页面过来的,那么就不做相关的响应

Cookie:http协议是无状态的,一个人发送了两次请求,服务器没有能力知道这两个请求是否来自同一个人,因此用cookie来做标识,一般想要做登录后才能访问的网站,那么就需要发送cookie信息
```

在Network中的headers中可以查看User-Agent,Referer和Cookie

![image-20240722104742204](C:\Users\liu\AppData\Roaming\Typora\typora-user-images\image-20240722104742204.png)

![image-20240722105047126](C:\Users\liu\AppData\Roaming\Typora\typora-user-images\image-20240722105047126.png)

#### 状态响应码:

```
状态响应码:Response Code
200:请求正常,服务器正常的返回数据
301:永久重定向,访问www.jingdong.com的时候会重定向到www.jd.com
302:临时重定向,访问一个需要登录的页面的时候,而此时没有登录,那么就会重定向到登录页面
400:请求的url在服务器找不到,即请求url错误
403:服务器拒绝访问,权限不够,或者是被反爬了
500:服务器内部错误,可能是服务器出现bug了,或者宕机了
```

状态响应码的详解，请看这篇文章:https://blog.csdn.net/2202_75922690/article/details/137112746

